{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f5b54d7-f087-467d-b8a0-a673f199924b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "import pickle\n",
    "from collections import defaultdict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d78afc28-bf8a-4915-97ad-1c28dd268a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SEQ_LENGTH = 1024\n",
    "\n",
    "def calculate_mace_outcomes(antihypertensive_starts, mace_data, index_col_name):\n",
    "    \"\"\"Calculate which patients had MACE within 12 months after antihypertensive start\"\"\"\n",
    "    # Convert only necessary columns to datetime\n",
    "    antihypertensive_starts.loc[:, index_col_name] = pd.to_datetime(antihypertensive_starts[index_col_name])\n",
    "    mace_data.loc[:, 'first_mace_date'] = pd.to_datetime(mace_data['first_mace_date'])\n",
    "    \n",
    "    # Use faster merge with pre-selected columns\n",
    "    outcomes = pd.merge(\n",
    "        antihypertensive_starts[['person_id', index_col_name]],\n",
    "        mace_data[['person_id', 'first_mace_date']],\n",
    "        on='person_id', \n",
    "        how='left'\n",
    "    )\n",
    "    print(outcomes.head())\n",
    "    # Vectorized operations\n",
    "    days_to_mace = np.zeros(len(outcomes), dtype=np.float32)\n",
    "    valid_dates = outcomes['first_mace_date'].notna()\n",
    "\n",
    "    if len(valid_dates) > 0:\n",
    "        days_to_mace[valid_dates] = (outcomes.loc[valid_dates, 'first_mace_date'] - \n",
    "                                    outcomes.loc[valid_dates, index_col_name]).apply(lambda x: x.days if pd.notna(x) else 0)\n",
    "    mace_12m = np.logical_and(days_to_mace >= 7, days_to_mace <= 365).astype(np.int8)\n",
    "    print(mace_12m.mean())\n",
    "    return pd.DataFrame({'person_id': outcomes['person_id'], 'mace_12m': mace_12m})\n",
    "\n",
    "def create_vocabulary(df):\n",
    "    \"\"\"Create vocabulary from single dataframe of concept IDs\"\"\"\n",
    "    # Use numpy for faster unique operation\n",
    "    unique_codes = np.unique(df['concept_id'].astype(np.int32)).astype(str)\n",
    "    \n",
    "    # Use dict comprehension instead of individual assignments\n",
    "    vocab = {**{code: idx+4 for idx, code in enumerate(unique_codes)},\n",
    "            **{'[PAD]': 0, '[CLS]': 1, '[SEP]': 2, '[DAY]': 3}}\n",
    "    return vocab\n",
    "\n",
    "def tokenize_patient_data(events_array, dates_array, vocab):\n",
    "    \"\"\"Optimized tokenization using numpy arrays\"\"\"\n",
    "    tokens = ['[CLS]']\n",
    "    current_date = None\n",
    "    \n",
    "    for date, concept_id in zip(dates_array, events_array):\n",
    "        if date != current_date:\n",
    "            if current_date is not None:\n",
    "                tokens.append('[SEP]')\n",
    "            tokens.append('[DAY]')\n",
    "            current_date = date\n",
    "        tokens.append(str(concept_id))\n",
    "    tokens.append('[SEP]')\n",
    "    \n",
    "    # Convert tokens to indices using list comprehension\n",
    "    token_ids = [vocab.get(token, vocab['[PAD]']) for token in tokens][-MAX_SEQ_LENGTH:]\n",
    "    return token_ids\n",
    "\n",
    "def process_patient_data(data, antihypertensive_starts, mace_data, index_col_name, suffix=\"\"):\n",
    "    \"\"\"Process patient data and create sequences with MACE outcomes\"\"\"\n",
    "    # Calculate MACE outcomes first\n",
    "    print(\"Calculating MACE outcomes...\")\n",
    "    mace_outcomes_df = calculate_mace_outcomes(antihypertensive_starts, mace_data, index_col_name)\n",
    "    \n",
    "    # Convert dates once\n",
    "    print(\"Converting dates...\")\n",
    "    data.loc[:, 'event_date'] = pd.to_datetime(data['event_date'])\n",
    "    data.loc[:, 'concept_id'] = data['concept_id'].astype(np.int32)\n",
    "    \n",
    "    # Pre-sort data\n",
    "    data.sort_values(['person_id', 'event_date'], inplace=True)\n",
    "    \n",
    "    # Create vocabulary\n",
    "    print(\"Creating vocabulary...\")\n",
    "    vocab = create_vocabulary(data)\n",
    "    \n",
    "    # Pre-merge outcomes\n",
    "    data = data.merge(mace_outcomes_df, on='person_id', how='left')\n",
    "    \n",
    "    # Group data once and convert to dictionary of arrays for faster access\n",
    "    print(\"Grouping patient data...\")\n",
    "    grouped_data = {\n",
    "        name: (\n",
    "            group['concept_id'].values,\n",
    "            group['event_date'].values,\n",
    "            group['mace_12m'].iloc[0]\n",
    "        )\n",
    "        for name, group in tqdm(data.groupby('person_id'))\n",
    "    }\n",
    "    \n",
    "    # Initialize arrays\n",
    "    n_patients = len(grouped_data)\n",
    "    padded_sequences = np.zeros((n_patients, MAX_SEQ_LENGTH), dtype=np.int32)\n",
    "    mace_outcomes = np.zeros(n_patients, dtype=np.float32)\n",
    "    sample_ids = np.empty(n_patients, dtype=object)\n",
    "    \n",
    "    # Process all patients\n",
    "    print(\"Processing sequences...\")\n",
    "    max_seq_length = 0\n",
    "    for i, (patient_id, (events, dates, mace)) in enumerate(tqdm(grouped_data.items())):\n",
    "        tokens = tokenize_patient_data(events, dates, vocab)\n",
    "        seq_len = min(len(tokens), MAX_SEQ_LENGTH)\n",
    "        padded_sequences[i, :seq_len] = tokens[:seq_len]\n",
    "        max_seq_length = max(max_seq_length, len(tokens))\n",
    "        mace_outcomes[i] = mace\n",
    "        sample_ids[i] = patient_id\n",
    "    \n",
    "    # Create mapping\n",
    "    sample_id_to_index = dict(zip(sample_ids, range(len(sample_ids))))\n",
    "    \n",
    "    # Save all data\n",
    "    print(\"Saving processed data...\")\n",
    "    np.save(f'./processed_data/transformer_input_sequences{suffix}.npy', padded_sequences)\n",
    "    np.save(f'./processed_data/transformer_input_lengths{suffix}.npy', \n",
    "            np.array([min(len(tokenize_patient_data(events, dates, vocab)), MAX_SEQ_LENGTH) \n",
    "                     for events, dates, _ in grouped_data.values()]))\n",
    "    np.save(f'./processed_data/transformer_mace_outcomes{suffix}.npy', mace_outcomes)\n",
    "    \n",
    "    with open(f'./processed_data/transformer_vocab{suffix}.pkl', 'wb') as f:\n",
    "        pickle.dump(vocab, f)\n",
    "    \n",
    "    pd.DataFrame(list(sample_id_to_index.items()), \n",
    "                columns=['person_id', 'index']).to_csv(\n",
    "                f'./processed_data/transformer_sample_id_to_index{suffix}.csv', index=False)\n",
    "    \n",
    "    # Print summary statistics\n",
    "    print(\"\\nSummary Statistics:\")\n",
    "    print(f\"Max sequence length: {max_seq_length}\")\n",
    "    print(f\"Vocabulary size: {len(vocab)}\")\n",
    "    print(f\"Number of patients: {n_patients}\")\n",
    "    print(f\"Shape of padded_sequences: {padded_sequences.shape}\")\n",
    "    print(f\"Shape of MACE_outcomes: {mace_outcomes.shape}\")\n",
    "    print(f\"Number of positive MACE outcomes: {mace_outcomes.sum()}\")\n",
    "    print(f\"MACE rate: {mace_outcomes.mean():.3f}\")\n",
    "    \n",
    "    return padded_sequences, mace_outcomes, vocab, sample_id_to_index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c21e959-fd79-4ef6-83ab-f4df7f53eb1b",
   "metadata": {},
   "source": [
    "## Remove dox patients from PT cohort and process PT data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a897293f-d103-43e7-9e66-7cfe0bb464d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./raw_data/dox_patients_1024_events_prior.csv',usecols=['person_id','concept_id','event_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1304884d-7f01-47ee-8762-e548ec93a389",
   "metadata": {},
   "outputs": [],
   "source": [
    "antihypertensive_data = pd.read_csv('./raw_data/antihypertensive_1024_events_prior_to_med_start.csv',usecols=['person_id','concept_id','event_date'])\n",
    "antihypertensive_data = antihypertensive_data[~antihypertensive_data['person_id'].isin(data['person_id'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afdf668e-dce6-46ec-9715-220cf53e87ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "dob_antihx = pd.read_csv('./raw_data/dob_antihypertensives.csv')\n",
    "age = antihypertensive_data.sort_values('event_date', ascending=True).drop_duplicates('person_id', keep='first').merge(dob_antihx, how='inner', on='person_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d0fc9d-2057-4712-bd19-cc554888106a",
   "metadata": {},
   "outputs": [],
   "source": [
    "age['event_date'] = pd.to_datetime(age['event_date'])\n",
    "age['birth_datetime'] = pd.to_datetime(age['birth_datetime'], format='mixed', dayfirst=False)\n",
    "age['age'] = (age['event_date']-age['birth_datetime']).dt.days / 365.25\n",
    "age[['age','person_id']].to_csv('./processed_data/age.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "785c45a7-3257-41b6-b223-5b4341c85e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dob_dox = pd.read_csv('./raw_data/dox_dob.csv')\n",
    "age_dox = data.sort_values('event_date', ascending=True).drop_duplicates('person_id', keep='first').merge(dob_dox, how='inner', on='person_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e0c5eb-d064-41be-bc6e-57945b93d40c",
   "metadata": {},
   "outputs": [],
   "source": [
    "age_dox['event_date'] = pd.to_datetime(age_dox['event_date'])\n",
    "age_dox['birth_datetime'] = pd.to_datetime(age_dox['birth_datetime'], format='mixed', dayfirst=False)\n",
    "age_dox['age'] = (age_dox['event_date']-age_dox['birth_datetime']).dt.days / 365.25\n",
    "age_dox[['age','person_id']].to_csv('./processed_data/age_dox.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d04fa5-059a-4ca7-8214-6e4ee0b3e32b",
   "metadata": {},
   "outputs": [],
   "source": [
    "antihypertensive_starts = pd.read_csv('./raw_data/antihypertensive_start.csv', usecols=['person_id','first_antihypertensive_date'])\n",
    "antihypertensive_starts = antihypertensive_starts[~antihypertensive_starts['person_id'].isin(data['person_id'])]\n",
    "\n",
    "mace_data = pd.read_csv('./raw_data/first_mace_post_antihypertensives.csv').drop('Unnamed: 0',axis=1)\n",
    "mace_data = mace_data[~mace_data['person_id'].isin(data['person_id'])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd6bbbe-bd58-4531-b49b-481dd43d8eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process everything\n",
    "sequences, outcomes, vocab, id_mapping = process_patient_data(antihypertensive_data, antihypertensive_starts, mace_data, 'first_antihypertensive_date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "806446ac-53d3-4375-a5b3-1bd32f462961",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate mortality outcomes\n",
    "deaths = pd.read_csv('./raw_data/death.csv')\n",
    "deaths['first_exposure_date'] = pd.to_datetime(deaths['first_exposure_date'])\n",
    "deaths['death_date'] = pd.to_datetime(deaths['death_date'])\n",
    "\n",
    "# Calculate days to death and create binary outcome\n",
    "deaths['days_to_death'] = (deaths['death_date'] - deaths['first_exposure_date']).dt.total_seconds() / (24 * 3600)\n",
    "deaths['death_12m'] = ((deaths['days_to_death'] >= 0) & \n",
    "                      (deaths['days_to_death'] <= 365)).fillna(0).astype(np.int8)\n",
    "\n",
    "# Create array aligned with our sequence data using the id_mapping\n",
    "death_outcomes = np.zeros(len(id_mapping), dtype=np.int8)\n",
    "death_dict = dict(zip(deaths['person_id'], deaths['death_12m']))\n",
    "\n",
    "# Use id_mapping dictionary directly\n",
    "for person_id, idx in id_mapping.items():\n",
    "    death_outcomes[idx] = death_dict.get(person_id, 0)\n",
    "\n",
    "# Save to file\n",
    "np.save('./processed_data/transformer_death_outcomes.npy', death_outcomes)\n",
    "\n",
    "# Print summary\n",
    "print(f\"Number of deaths within 12 months: {death_outcomes.sum()}\")\n",
    "print(f\"12-month mortality rate: {death_outcomes.mean():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "406d4b9d-de31-45c9-a9bc-3cbad35e7b0e",
   "metadata": {},
   "source": [
    "## Rest of data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edeb8ac3-6057-4cc4-b7e4-952c016d3386",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "263b5ce3-ac0c-4a63-9b13-4e2fc2a52896",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your data files - skip if you already have them loaded\n",
    "data = pd.read_csv('./raw_data/dox_patients_1024_events_prior.csv',usecols=['person_id','concept_id','event_date'])\n",
    "antihypertensive_starts = pd.read_csv('./raw_data/dox_start.csv')\n",
    "mace_data = pd.read_csv('./raw_data/first_mace_post_dox.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c525982-38fa-47f9-90b1-3b4662ed3263",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Process everything\n",
    "sequences, outcomes, vocab, id_mapping = process_patient_data(data, antihypertensive_starts, mace_data, 'first_doxorubicin_date','_FT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e98f2b84-bad0-43f8-beb3-67a61fe127bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate mortality outcomes\n",
    "deaths = pd.read_csv('./raw_data/dox_death.csv')\n",
    "deaths['first_exposure_date'] = pd.to_datetime(deaths['first_exposure_date'])\n",
    "deaths['death_date'] = pd.to_datetime(deaths['death_date'])\n",
    "\n",
    "# Calculate days to death and create binary outcome\n",
    "deaths['days_to_death'] = (deaths['death_date'] - deaths['first_exposure_date']).dt.total_seconds() / (24 * 3600)\n",
    "deaths['death_12m'] = ((deaths['days_to_death'] >= 0) & \n",
    "                      (deaths['days_to_death'] <= 365)).fillna(0).astype(np.int8)\n",
    "\n",
    "# Create array aligned with our sequence data using the id_mapping\n",
    "death_outcomes = np.zeros(len(id_mapping), dtype=np.int8)\n",
    "death_dict = dict(zip(deaths['person_id'], deaths['death_12m']))\n",
    "\n",
    "# Use id_mapping dictionary directly\n",
    "for person_id, idx in id_mapping.items():\n",
    "    death_outcomes[idx] = death_dict.get(person_id, 0)\n",
    "\n",
    "# Save to file\n",
    "np.save('./processed_data/transformer_death_outcomes_FT.npy', death_outcomes)\n",
    "\n",
    "# Print summary\n",
    "print(f\"Number of deaths within 12 months: {death_outcomes.sum()}\")\n",
    "print(f\"12-month mortality rate: {death_outcomes.mean():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec5a8bc-3fa3-4a0f-a970-f31094bd96de",
   "metadata": {},
   "outputs": [],
   "source": [
    "mace_data = pd.read_csv('./raw_data/first_mace_post_antihypertensives.csv').drop('Unnamed: 0',axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30cb9486-4ee0-4741-af6c-2a07e135a0c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dox_mace = mace_data[mace_data['person_id'].isin(data['person_id'])].drop('Unnamed: 0',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6766022-d76e-434f-8d57-79d0d4ddce52",
   "metadata": {},
   "outputs": [],
   "source": [
    "dox_mace['first_exposure_date'] = pd.to_datetime(dox_mace['first_exposure_date'])\n",
    "dox_mace['first_mace_date'] = pd.to_datetime(dox_mace['first_mace_date'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e2196f7-792d-4637-9006-a7852d56f24d",
   "metadata": {},
   "outputs": [],
   "source": [
    "samson = dox_mace[\n",
    "    (dox_mace['first_mace_date'] - dox_mace['first_exposure_date']).dt.days.between(7, 365, inclusive='both')\n",
    "]\n",
    "samson.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9bcdadc-2450-4a0d-bc69-51f5ad460e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "shreya = pd.read_csv('./shreya_positive_class.csv')\n",
    "shreya.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "227a30e2-be2c-41eb-ba01-135ec1db95ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = samson.merge(shreya, how='outer',left_on='person_id', right_on='patient_id')\n",
    "df['prediction_time'] = pd.to_datetime(df['prediction_time'])\n",
    "diff_pats = np.union1d((df[df['prediction_time'] != df['first_exposure_date']])['person_id'], (df[df['prediction_time'] != df['first_exposure_date']])['patient_id'])\n",
    "df[df['prediction_time'] != df['first_exposure_date']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc389a9-50c3-4c97-94fa-9966eee869d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dox_mace.to_csv('./samson_mace_data_dox_cohort.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a17f77-5fbe-43d9-91e2-153a9968a588",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to datetime\n",
    "dox_mace['first_exposure_date'] = pd.to_datetime(dox_mace['first_exposure_date'])\n",
    "dox_mace['first_mace_date'] = pd.to_datetime(dox_mace['first_mace_date'])\n",
    "\n",
    "# Calculate days and label using the same logic as original code\n",
    "days_to_mace = np.zeros(len(dox_mace), dtype=np.float32)\n",
    "valid_dates = dox_mace['first_mace_date'].notna()\n",
    "\n",
    "if len(valid_dates) > 0:\n",
    "    days_to_mace[valid_dates] = (dox_mace.loc[valid_dates, 'first_mace_date'] - \n",
    "                                dox_mace.loc[valid_dates, 'first_exposure_date']).apply(lambda x: x.days if pd.notna(x) else 0)\n",
    "\n",
    "dox_mace['label'] = np.logical_and(days_to_mace >= 7, days_to_mace <= 365).astype(np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "542107dd-db07-4c1f-a0de-4d8f3a2727e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
